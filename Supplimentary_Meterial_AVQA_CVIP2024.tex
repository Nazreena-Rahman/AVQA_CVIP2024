\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%

\usepackage{tabularray}
%usepackage{amsmath,amssymb,amsfonts}%
\usepackage{graphicx}%
\usepackage{rotating}
\usepackage{multirow}%
\usepackage{subfiles}
\usepackage{comment}
\usepackage{amsmath} 
\usepackage{multicol}
\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{lineno}
\usepackage{algpseudocode}%
\usepackage{amssymb}
\usepackage{xcolor}%
\usepackage{fontspec}
\usepackage{pifont}
\usepackage{subcaption}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{subfig}
\usepackage{booktabs}
%\usepackage{lineno}
\usepackage[hidelinks]{hyperref}

%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
\usepackage{color}
\usepackage{enumitem}
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{\baselineskip}{\baselineskip}
\setlength{\parskip}{0pt}
\setlength{\textfloatsep}{10pt plus 1pt minus 2pt}
\setlength{\floatsep}{10pt plus 1pt minus 2pt}
\setlength{\intextsep}{10pt plus 1pt minus 2pt}

%\renewcommand\UrlFont{\color{blue}\rmfamily}
%
\newfontfamily\bengalifont[Script=Bengali]{Noto Serif Bengali}
\begin{document}
% \linenumbers

\title{Supplementary Material for \\ TDIUC-AVQA: A Visual Question Answering Dataset in Low-Resource Assamese Language}


\titlerunning{Visual Question Answering in Low-Resource Assamese Language}

\author{Nazreena Rahman \inst{1} \orcidID{0000-0001-7188-0111} \and Pankaj Choudhury \inst{2} \orcidID{0009-0001-1159-3118} \and Prithwijit Guha \inst{1, 2} \orcidID{0000-0003-2885-0026} \and Ashish Anand  \inst{2, 3} \orcidID{0000-0002-0024-3358} \and Sukumar   Nandi \inst{2, 3} \orcidID{0000-0002-5869-1057}}

\institute{Department of Electronics and Electrical Engineering \and Centre for Linguistic Science and Technology \and Department of Computer Science and Engineering \\ Indian Institute of Technology Guwahati, Assam, India \\
%\email{lncs@springer.com}\\
%\url{http://www.springer.com/gp/computer-science/lncs} \and ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
\email{\{nazreena, pankajchoudhury, pguha, anand.ashish, sukumar\}@iitg.ac.in}}
%

%\begin{document}

\maketitle              % typeset the header of the contribution
%
% \begin{abstract}

% \end{abstract}
%

\section{Results and Discussion}

The initial experiment focused on training the proposed models on the TDIUC-AVQA dataset, with the RNN layer size increased up to 5. As shown in Table \ref{Q2}, the test results indicate that Bi-GRU achieved the highest precision and recall scores for layer 1. For layer 2, BiGRU obtained the highest F1-score and accuracy values when using soft attention. The evaluation results confirm that the BiGRU model outperforms other models as a question encoder.

\begin{table}[!hbtp]
\caption{Performance comparison of the proposed AVQA method using various question encoders across different RNN layers with Soft Attention on the TDIUC-AVQA dataset}
\label{Q2}
\begin{tabular}{|c|c|c|c|c|c|}
\toprule
\textbf{Question Encoder} & \textbf{No. of RNN Layers} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} & \textbf{Accuracy} \\
\hline
\multirow{5}{*}{LSTM}   & 1 & 79.17                & 75.96                & 76.4                 & 75.75                \\
                        & 2 & 80.41                & 77.72                & 77.96                & 77.6                 \\ 
                        & 3 & 80.25                & 77.93                & 78.06                & 77.81                \\ 
                        & 4 & 80.59                & 78.13                & 78.35                & 77.99                \\ 
                        & 5 & 80.24                & 77.66                & 77.97                & 77.52                \\ \hline
\multirow{5}{*}{Bi-LSTM} & 1 & 80.88                & 79.88                & 79.87                & 79.73                \\ 

                        & 2 & 80.09 & 77.50 & 77.77  &77.34 \\ 
                        & 3 & 80.66 & 79.12 & 79.38 & 79.01 \\ 
                        & 4 & 80.83                & 78.68                & 78.91                & 78.18                \\ 
                        & 5 & 80.46                & 78.07                & 78.62                & 77.96                \\ \hline
\multirow{5}{*}{GRU}    & 1 & 80.14                & 79.27                & 79.22                & 79.13                \\ 
                        & 2 &  79.74 &	77.94 &	78.2	& 77.79 \\ 
                        & 3 &  80.57 & 77.89 & 77.99 & 77.73\\ 
                        & 4 & 80.22 & 77.17 & 77.66 & 77.06 \\
                        & 5 & 80.14 & 77.45 & 77.75 & 77.30 \\ \hline
\multirow{5}{*}{Bi-GRU}  & 1 & 80.91                & \textbf{80.27}       & 79.99                & \textbf{80.1}        \\ 
                        & 2 & \textbf{81.22}       & 80.21                & \textbf{80.31}       & 80.07                \\ 
                        & 3 & 80.48                & 77.78                & 78.15                & 77.64                \\ 
                        & 4 & 80.91                & 78.8                 & 79.13                & 78.69                \\ 
                        & 5 & 80.85                & 78.65                & 79.01                & 78.53    \\ \hline
%\cmidrule{1-6}
\multirow{5}{*}{Transformer} & 1                 & 76.74     & 76.42  & 76.03 & 76.16    \\
\multirow{5}{*}{Encoder}                               & 2                 & 77.44     & 78.02  & 77.77 & 77.25    \\ 
                             & 3                 & 76.21     & 77.49  & 76.42 & 77.26    \\ 
                             & 4                 & 76.48     & 77.58  & 76.68 & 77.37    \\ 
                             & 5                 & 20.05     & 24.98  & 20.71 & 24.25    \\ \hline
\end{tabular}
\end{table}


\begin{table}[!t]
\centering
\caption{Performance evaluation of the proposed AVQA method on data excluding samples from the \emph{Absurd} category during training}
\label{without_absurd}
\begin{tabular}{|c|c|c|c|c|}
\toprule
{\textbf{Question Category Wise}}           & {\textbf{Precision}} & {\textbf{Recall}} & {\textbf{F1}}    & {\textbf{Accuracy}} \\
\hline
Object Presence               &  91.27    &  91.27  & 91.27  & 91.27    \\ \hline
Subordinate Object Recognition              & 82.31 & 82.82 &  81.61  & 81.32   \\ \hline
Counting               & 44.75 &	44.56 &	38.66	& 44.55 \\ \hline
Color Attributes    &      47.83 & 45.48 & 44.14 &   45.29 \\ \hline
Other Attributes &	41.73 &	45.09 & 40.76 &  40.24	   \\ \hline
Activity Recognition           &       53.98  & 48.01  & 46.96    & 47.73\\ \hline
Sport Recognition              & {\textbf{93.04}} & {\textbf{92.32}} & {\textbf{92.58}}  &{\textbf{92.18}}   \\ \hline
Positional Reasoning          & 23.65 &	29.18 &	 22.54	&  24.09   \\ \hline
Scene Classification           & 73.34    & 55.60 & 63.25 & 60.17  \\ \hline
Sentiment Understanding &   53.42	& 51.72 &	51.96 &	 47.48  \\ \hline
Utility/Affordance    & 63.53      & 32.00     &  33.85 &  14.04   \\
\hline
\end{tabular}
\end{table}    
Table \ref{without_absurd} shows a decrease in category-wise performance when the proposed AVQA model is trained without \emph{Absurd} category. This suggests that including the \emph{Absurd} category in training helps mitigate language prior bias, thereby enhancing model performance. 
\end{document}